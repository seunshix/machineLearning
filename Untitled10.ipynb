{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnIpqBbyuO8FSJxYHDpZlU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunshix/machineLearning/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luAXG-6fY8fe",
        "outputId": "2755fe31-d3bc-4ba3-f4e0-e986de77f65d"
      },
      "source": [
        "#######################################################################\n",
        "# Copyright (C)                                                       #\n",
        "# 2016-2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)             #\n",
        "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\n",
        "# Permission given to modify the code as long as you keep this        #\n",
        "# declaration at the top                                              #\n",
        "#######################################################################\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.table import Table\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "ROWS = 4\n",
        "COLUMNS = 2\n",
        "DISCOUNT = 0.6666\n",
        "\n",
        "# left, up, right, down\n",
        "ACTIONS = [np.array([0, -1]),\n",
        "           np.array([-1, 0]),\n",
        "           np.array([0, 1]),\n",
        "           np.array([1, 0])]\n",
        "ACTIONS_FIGS=[ '←', '↑', '→', '↓']\n",
        "\n",
        "\n",
        "ACTION_PROB = 0.25\n",
        "\n",
        "def is_terminal(state):\n",
        "  x, y = state\n",
        "  return(x == 0 and y == 0) or (x == 1 and y == 2) or (x == 1 and y == 3) or (x == COLUMNS - 1 and y == ROWS - 1)\n",
        "\n",
        "def step(state, action):\n",
        "  if is_terminal(state):\n",
        "    return state, 0\n",
        "\n",
        "  next_state = (np.array(state) + action).tolist()\n",
        "  x, y = next_state\n",
        "   \n",
        "  if x < 0 or x >= COLUMNS or y < 0 or y >= ROWS:\n",
        "    next_state = state\n",
        "    \n",
        "  reward = -3.0\n",
        "    \n",
        "  return next_state, reward\n",
        "\n",
        "def draw_policy(optimal_values):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_axis_off()\n",
        "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
        "\n",
        "    nrows, ncols = optimal_values.shape\n",
        "    width, height = 1.0 / ncols, 1.0 / nrows\n",
        "\n",
        "    # Add cells\n",
        "    for (i, j), val in np.ndenumerate(optimal_values):\n",
        "        next_vals=[]\n",
        "        for action in ACTIONS:\n",
        "            next_state, _ = step([i, j], action)\n",
        "            next_vals.append(optimal_values[next_state[0],next_state[1]])\n",
        "\n",
        "        best_actions=np.where(next_vals == np.max(next_vals))[0]\n",
        "        val=''\n",
        "        for ba in best_actions:\n",
        "            val+=ACTIONS_FIGS[ba]        \n",
        "        tb.add_cell(i, j, width, height, text=val,\n",
        "                loc='center', facecolor='white')\n",
        "\n",
        "    # Row and column labels...\n",
        "    for i in range(len(optimal_values)):\n",
        "        tb.add_cell(i, -1, width, height, text=i+1, loc='right',\n",
        "                    edgecolor='none', facecolor='none')\n",
        "        tb.add_cell(-1, i, width, height/2, text=i+1, loc='center',\n",
        "                   edgecolor='none', facecolor='none')\n",
        "\n",
        "    ax.add_table(tb)\n",
        "\n",
        "\n",
        "def draw_image(image):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_axis_off()\n",
        "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
        "\n",
        "    nrows, ncols = image.shape\n",
        "    width, height = 1.0 / ncols, 1.0 / nrows\n",
        "\n",
        "    # Add cells\n",
        "    for (i, j), val in np.ndenumerate(image):\n",
        "        tb.add_cell(i, j, width, height, text=val,\n",
        "                    loc='center', facecolor='white')\n",
        "\n",
        "        # Row and column labels...\n",
        "    for i in range(len(image)):\n",
        "        tb.add_cell(i, -1, width, height, text=i+1, loc='right',\n",
        "                    edgecolor='none', facecolor='none')\n",
        "        tb.add_cell(-1, i, width, height/2, text=i+1, loc='center',\n",
        "                    edgecolor='none', facecolor='none')\n",
        "    ax.add_table(tb)\n",
        "\n",
        "\n",
        "def compute_state_value(in_place=True, discount=1.0):\n",
        "    new_state_values = np.zeros((COLUMNS, ROWS))\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        if in_place:\n",
        "            state_values = new_state_values\n",
        "        else:\n",
        "            state_values = new_state_values.copy()\n",
        "        old_state_values = state_values.copy()\n",
        "\n",
        "        for i in range(COLUMNS):\n",
        "            for j in range(ROWS):\n",
        "                value = 0\n",
        "                for action in ACTIONS:\n",
        "                    (next_i, next_j), reward = step([i, j], action)\n",
        "                    value += ACTION_PROB * (reward + discount * state_values[next_i, next_j])\n",
        "                new_state_values[i, j] = value\n",
        "\n",
        "        max_delta_value = abs(old_state_values - new_state_values).max()\n",
        "        if max_delta_value < 1e-4:\n",
        "            break\n",
        "\n",
        "        iteration += 1\n",
        "\n",
        "    return new_state_values, iteration\n",
        "\n",
        "def figure_3_2():\n",
        "    value = np.zeros((COLUMNS, ROWS))\n",
        "    while True:\n",
        "        # keep iteration until convergence\n",
        "        new_value = np.zeros_like(value)\n",
        "        for i in range(COLUMNS):\n",
        "            for j in range(ROWS):\n",
        "                for action in ACTIONS:\n",
        "                    (next_i, next_j), reward = step([i, j], action)\n",
        "                    # bellman equation\n",
        "                    new_value[i, j] += ACTION_PROB * (reward + DISCOUNT * value[next_i, next_j])\n",
        "        if np.sum(np.abs(value - new_value)) < 1e-4:\n",
        "            draw_image(np.round(new_value, decimals=2))\n",
        "            plt.savefig('figure_3_2.png')\n",
        "            plt.close()\n",
        "            break\n",
        "        value = new_value\n",
        "\n",
        "def figure_3_2_linear_system():\n",
        "    '''\n",
        "    Here we solve the linear system of equations to find the exact solution.\n",
        "    We do this by filling the coefficients for each of the states with their respective right side constant.\n",
        "    '''\n",
        "    A = -1 * np.eye(COLUMNS * ROWS)\n",
        "    b = np.zeros(COLUMNS * ROWS)\n",
        "    for i in range(COLUMNS):\n",
        "        for j in range(ROWS):\n",
        "            s = [i, j]  # current state\n",
        "            index_s = np.ravel_multi_index(s, (COLUMNS, ROWS))\n",
        "            for a in ACTIONS:\n",
        "                s_, r = step(s, a)\n",
        "                index_s_ = np.ravel_multi_index(s_, (COLUMNS, ROWS))\n",
        "\n",
        "                A[index_s, index_s_] += ACTION_PROB * DISCOUNT\n",
        "                b[index_s] -= ACTION_PROB * r\n",
        "\n",
        "    x = np.linalg.solve(A, b)\n",
        "    draw_image(np.round(x.reshape(COLUMNS, ROWS), decimals=2))\n",
        "    plt.savefig('figure_3_2_linear_system.png')\n",
        "    plt.close()\n",
        "\n",
        "def figure_3_5():\n",
        "    value = np.zeros((COLUMNS, ROWS))\n",
        "    while True:\n",
        "        # keep iteration until convergence\n",
        "        new_value = np.zeros_like(value)\n",
        "        for i in range(COLUMNS):\n",
        "            for j in range(ROWS):\n",
        "                values = []\n",
        "                for action in ACTIONS:\n",
        "                    (next_i, next_j), reward = step([i, j], action)\n",
        "                    # value iteration\n",
        "                    values.append(reward + DISCOUNT * value[next_i, next_j])\n",
        "                new_value[i, j] = np.max(values)\n",
        "        if np.sum(np.abs(new_value - value)) < 1e-4:\n",
        "            draw_image(np.round(new_value, decimals=2))\n",
        "            plt.savefig('figure_3_5.png')\n",
        "            plt.close()\n",
        "            draw_policy(new_value)\n",
        "            plt.savefig('figure_3_5_policy.png')\n",
        "            plt.close()\n",
        "            break\n",
        "        value = new_value\n",
        "def figure_4_1():\n",
        "    # While the author suggests using in-place iterative policy evaluation,\n",
        "    # Figure 4.1 actually uses out-of-place version.\n",
        "    _, asycn_iteration = compute_state_value(in_place=True)\n",
        "    values, sync_iteration = compute_state_value(in_place=False)\n",
        "    draw_image(np.round(values, decimals=2))\n",
        "    print('In-place: {} iterations'.format(asycn_iteration))\n",
        "    print('Synchronous: {} iterations'.format(sync_iteration))\n",
        "\n",
        "    plt.savefig('figure_4_1.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    figure_4_1()\n",
        "    figure_3_2_linear_system()\n",
        "    figure_3_2()\n",
        "    figure_3_5()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In-place: 29 iterations\n",
            "Synchronous: 36 iterations\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}