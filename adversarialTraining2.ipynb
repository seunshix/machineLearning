{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adversarialTraining2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmm1hqumiRBQGsl5WfJLnf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seunshix/machineLearning/blob/main/adversarialTraining2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "2iFcHbQ8RqNs",
        "outputId": "9331e8ce-9e15-458c-a971-2ccb51c9996d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "# loading test and train data\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "trainfile = open(\"train.txt\", \"r\")\n",
        "for line in trainfile:\n",
        "    x = line.split()\n",
        "    row = []\n",
        "    count = 0\n",
        "    for val in x:\n",
        "        if count == 0:\n",
        "            y_train.append(float(val))\n",
        "        else:\n",
        "            row.append(val)\n",
        "        count = count + 1\n",
        "    x_train.append(row)\n",
        "\n",
        "trainfile.close()\n",
        "xtrain = np.asarray(x_train)\n",
        "ytrain = np.asarray(y_train)\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "testfile = open(\"test.txt\", \"r\")\n",
        "for line in testfile:\n",
        "    x = line.split()\n",
        "    row = []\n",
        "    count = 0\n",
        "    for val in x:\n",
        "        if count == 0:\n",
        "            y_test.append(float(val))\n",
        "        else:\n",
        "            row.append(val)\n",
        "        count = count + 1\n",
        "    x_test.append(row)\n",
        "\n",
        "testfile.close()\n",
        "xtest = np.asarray(x_test)\n",
        "ytest = np.asarray(y_test)\n",
        "\n",
        "def load_real_samples():\n",
        "    dataset = (xtrain, ytrain ), (_, _)\n",
        "    # expand to 3d, e.g add channels dimension\n",
        "    X = np.expand_dims(xtrain, axis=-1)\n",
        "    # convert from unsigned ints to floats\n",
        "    X = X.reshape((xtrain.shape[0], 16, 16, 1)).astype('float32')\n",
        "    #Normalize the images to [-1,1]\n",
        "    X = (X - 127.5)/127.5 \n",
        "\n",
        "    return X\n",
        "\n",
        "BUFFER_SIZE = 7291\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(load_real_samples()).shuffle(BUFFER_SIZE).batch(BATCH_SIZE) \n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(4*4*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((4, 4, 256)))\n",
        "    assert model.output_shape == (None, 4, 4, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (2, 2), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 4, 4, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 8, 8, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (2, 2), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 16, 16, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray_r')\n",
        "\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[16, 16, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)\n",
        "\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam\n",
        "\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "\n",
        "EPOCHS = 500\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)\n",
        "  \n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray_r')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "\n",
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "display_image(EPOCHS)\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.00419992]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3351dacf35b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m                                  \u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscriminator_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                                  \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                                  discriminator=discriminator)\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, **kwargs)\u001b[0m\n\u001b[1;32m   1927\u001b[0m       \u001b[0;31m# v to a Trackable data structure when v is a list/dict/tuple.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m       \u001b[0mconverted_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m       \u001b[0m_assert_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_assert_trackable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;34m\"object should be trackable (i.e. it is part of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;34m\"TensorFlow Python API and manages state), please open an issue.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m         .format(obj))\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `Checkpoint` was expecting a trackable object (an object derived from `TrackableBase`), got <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>. If you believe this object should be trackable (i.e. it is part of the TensorFlow Python API and manages state), please open an issue."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "FILB8lZfpvW-",
        "outputId": "63062bbd-bde1-40f3-87ad-424a24d6f3a9"
      },
      "source": [
        "pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-xcdd03qo\n",
            "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-xcdd03qo\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs===0.0.0fb84a692843e9b42585733ca4078b4bd5e459f5c-) (0.8.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs===0.0.0fb84a692843e9b42585733ca4078b4bd5e459f5c-) (0.10.0)\n",
            "Collecting protobuf>=3.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/32/06ac05342b5b77aa5ad4f0ffd5df32eea9092cd8db55f9472d55acab92e2/protobuf-3.15.5-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from tensorflow-docs===0.0.0fb84a692843e9b42585733ca4078b4bd5e459f5c-) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->tensorflow-docs===0.0.0fb84a692843e9b42585733ca4078b4bd5e459f5c-) (1.15.0)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0fb84a692843e9b42585733ca4078b4bd5e459f5c_-cp37-none-any.whl size=147330 sha256=37a3eb7279addc11c190201035349bd6e29859fa8bd3781ad1af3d4e1c24c1d6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1sh774py/wheels/eb/1b/35/fce87697be00d2fc63e0b4b395b0d9c7e391a10e98d9a0d97f\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: protobuf, tensorflow-docs\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "Successfully installed protobuf-3.15.5 tensorflow-docs-0.0.0fb84a692843e9b42585733ca4078b4bd5e459f5c-\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}